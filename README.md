# Diabetes-Hospital-Readmission-Predictor
[Click here](https://nbviewer.org/github/hmcooper1/Diabetes-Hospital-Readmission-Predictor/blob/main/diabetes_hospital_readmission.ipynb) to view the full notebook on NBViewer.
## Overview
This project aims to create a binary classification model to predict whether or not a diabetes patient who was admitted to the hospital will be readmitted. This predictive model can help healthcare providers identify high-risk patients early, enabling targeted interventions and improving care management. This analysis can also help identify key risk factors that contribute to hospital readmissions among diabetes patients. Ultimately, the goal is to reduce avoidable readmissions, optimize hospital resources, and support data-driven decision-making in healthcare settings.

## Data Sources
This data is from the UC Irvine Machine Learning Repository, and can be accessed [here](https://archive.ics.uci.edu/dataset/296/diabetes+130-us+hospitals+for+years+1999-2008). It contains data from 130 different US hospitals and integrated delivery networks for over ten years (1999-2008). The data is extracted from a national data warehouse that collects clinical records in US hospitals - the Health Facts database (Cerner Corporation, Kansas City, MO). The data includes patient demographics, ICM-9 codes, in-hospital procedures, encounters (inpatient, outpatient, emergency), medical usage, lab test results, and hospital visit details. There are 101,766 encounters included and 75,518 from unique patients.

## Models
Three different classification models were implemented: logistic regression, random forest, and XGBoost. These models were chosen to compare a baseline linear approach (logistic regression) with more advanced ensemble methods (random forest and XGBoost).

## Results
Model performance was not very high. The logistic regression model performed the worst, with an AUC value of 0.64, precision of 0.58, and recall of 0.24. The random forest model had an AUC value of 0.66, precision of 0.45, and recall of 0.92. The XGBoost model had an AUC value of 0.66, precision of 0.45, and recall of 0.89. SHAP analysis revealed that both the random forest and XGBoost models identified the same seven features as the most important. The top three were: number of hospital visits in the past year, number of diagnoses entered to the system on that encounter, and age. For all three variables, higher values were associated with a higher likelihood of readmission.

## Conclusions
This demonstrates the possibility of using machine learning models to predict hospital readmissions among diabetes patients using administrative and clinical data. While random forest and XGBoost models outperformed logistic regression, their overall performance remained modest, with AUC values around 0.66. Precision was relatively low across models, although recall was high for the ensemble models, suggesting they are better at identifying patients who will be readmitted but at the cost of many false positives. SHAP analysis revealed that both the random forest and XGBoost models consistently identified the same top features - including number of prior hospital visits, number of diagnoses, and age - as most important for predicting readmission. Hospitals could use thresholds on these variables to flag high-risk patients for targeted follow-up or discharge planning interventions. This data is limited by missing values, reliance on coarse groupings (age bins, ICD-9 codes), and lack of longitudinal information or social context - all which may restrict the model's ability to fully capture readmission risk. Ultimately, the dataset may simply not contain enough predictive signal to support strong performance, highlighting the need for more detailed data sources for future work. Future research could explore further feature engineering, temporal modeling, or neural network architectures to improve predictive performance.
